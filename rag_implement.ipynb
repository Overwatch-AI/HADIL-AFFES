{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-6.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (0.3.11)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (0.3.80)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.4.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.25.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.3.1)\n",
      "Downloading pypdf-6.3.0-py3-none-any.whl (328 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m328.9/328.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf, PyMuPDF, faiss-cpu\n",
      "Successfully installed PyMuPDF-1.26.6 faiss-cpu-1.13.0 pypdf-6.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf langchain-text-splitters sentence-transformers faiss-cpu google-generativeai python-dotenv PyMuPDF Pillow\n",
    "!pip install -q rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pickle\n",
    "from rank_bm25 import BM25Okapi\n",
    "import google.generativeai as genai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: EXTRACTING AND CLASSIFYING PAGES\n",
      "================================================================================\n",
      " Total pages: 146\n",
      "   Diagram pages: 67\n",
      "   Text pages: 79\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: EXTRACT AND CLASSIFY PAGES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: EXTRACTING AND CLASSIFYING PAGES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "pdf_path = \"/content/drive/MyDrive/boing_RAG/Boeing B737 Manual.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "pages = []\n",
    "\n",
    "for i, page in enumerate(doc):\n",
    "    text = page.get_text()\n",
    "    text_length = len(text.strip())\n",
    "\n",
    "    images = page.get_images()\n",
    "\n",
    "    # Render page at low res to analyze visual density\n",
    "    pix = page.get_pixmap(dpi=72)\n",
    "    img_bytes = pix.tobytes(\"png\")\n",
    "    img = Image.open(io.BytesIO(img_bytes))\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = img.convert('L')\n",
    "    pixels = np.array(gray)\n",
    "\n",
    "    # Calculate \"ink density\"\n",
    "    non_white_pixels = np.sum(pixels < 240)\n",
    "    total_pixels = pixels.size\n",
    "    ink_density = non_white_pixels / total_pixels\n",
    "\n",
    "    # Check for intentionally blank\n",
    "    is_blank = \"intentionally blank\" in text.lower()\n",
    "\n",
    "    # Classification: Diagram if high ink density or has images\n",
    "    is_diagram = (\n",
    "        len(images) > 0 or\n",
    "        (ink_density > 0.14 and not is_blank)\n",
    "    )\n",
    "\n",
    "    page_data = {\n",
    "        \"page_number\": i + 1,\n",
    "        \"text\": text.strip(),\n",
    "        \"char_count\": text_length,\n",
    "        \"has_images\": len(images) > 0,\n",
    "        \"ink_density\": ink_density,\n",
    "        \"is_blank\": is_blank,\n",
    "        \"is_diagram\": is_diagram,\n",
    "        \"page_image\": None\n",
    "    }\n",
    "\n",
    "    pages.append(page_data)\n",
    "\n",
    "# Render only diagram pages at high resolution\n",
    "for i, page_data in enumerate(pages):\n",
    "    if page_data[\"is_diagram\"]:\n",
    "        page = doc[i]\n",
    "        pix = page.get_pixmap(dpi=150)\n",
    "        page_data[\"page_image\"] = pix.tobytes(\"png\")\n",
    "\n",
    "doc.close()\n",
    "\n",
    "diagram_pages = [p[\"page_number\"] for p in pages if p[\"is_diagram\"]]\n",
    "text_pages = [p[\"page_number\"] for p in pages if not p[\"is_diagram\"]]\n",
    "\n",
    "print(f\" Total pages: {len(pages)}\")\n",
    "print(f\"   Diagram pages: {len(diagram_pages)}\")\n",
    "print(f\"   Text pages: {len(text_pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: IDENTIFYING PERFORMANCE TABLE PAGES (IMPROVED)\n",
      "================================================================================\n",
      "‚úÖ Found 6 performance table pages\n",
      "\n",
      "üìÑ Performance table pages: [40, 41, 82, 83, 85, 86]\n",
      "   Page 39 is performance table: False\n",
      "   Page 126 is performance table: False\n",
      "   flap_retraction: [40, 41]\n",
      "   field_climb_limits: [82, 83, 85, 86]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# IMPROVED STEP 2: BETTER PERFORMANCE TABLE IDENTIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: IDENTIFYING PERFORMANCE TABLE PAGES (IMPROVED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "performance_table_pages = {}\n",
    "\n",
    "for page in pages:\n",
    "    content = page['text']\n",
    "    content_lower = content.lower()\n",
    "\n",
    "    is_perf_table = False\n",
    "    table_info = {}\n",
    "\n",
    "    # Pattern 1: Field & Climb Limit Weights tables (STRICTER)\n",
    "    # Must have BOTH \"limit weight\" AND \"pressure altitude\" AND table structure\n",
    "    if (('field limit weight' in content_lower or 'climb limit' in content_lower) and\n",
    "        'pressure altitude' in content_lower and\n",
    "        ('1000 kg' in content_lower or 'corr' in content_lower)):  # Table structure indicators\n",
    "\n",
    "        alt_match = re.search(r'(\\d+)\\s*FT\\s*Pressure\\s*Altitude', content, re.IGNORECASE)\n",
    "        if alt_match:\n",
    "            altitude = alt_match.group(1)\n",
    "\n",
    "            runway_condition = \"unknown\"\n",
    "            if \"wet runway\" in content_lower:\n",
    "                runway_condition = \"wet\"\n",
    "            elif \"dry runway\" in content_lower:\n",
    "                runway_condition = \"dry\"\n",
    "\n",
    "            flap_match = re.search(r'Flaps?\\s*(\\d+)', content, re.IGNORECASE)\n",
    "            flap_setting = flap_match.group(1) if flap_match else None\n",
    "\n",
    "            table_info = {\n",
    "                \"type\": \"field_climb_limits\",\n",
    "                \"altitude\": altitude,\n",
    "                \"runway_condition\": runway_condition,\n",
    "                \"flap_setting\": flap_setting\n",
    "            }\n",
    "            is_perf_table = True\n",
    "\n",
    "    # Pattern 2: Flap retraction tables\n",
    "    elif ('flap' in content_lower and 'retraction' in content_lower and\n",
    "          'speed' in content_lower and 't/o' in content_lower):\n",
    "        table_info = {\n",
    "            \"type\": \"flap_retraction\",\n",
    "            \"altitude\": None,\n",
    "            \"runway_condition\": None\n",
    "        }\n",
    "        is_perf_table = True\n",
    "\n",
    "    # Pattern 3: Landing field limit tables\n",
    "    elif ('landing field limit' in content_lower and\n",
    "          'wind corr' in content_lower):\n",
    "        table_info = {\n",
    "            \"type\": \"landing_limits\",\n",
    "            \"altitude\": None,\n",
    "            \"runway_condition\": None\n",
    "        }\n",
    "        is_perf_table = True\n",
    "\n",
    "    # DON'T classify as performance table if it's clearly a procedure\n",
    "    ''' if is_perf_table:\n",
    "        # Exclude procedure pages\n",
    "        if any(keyword in content_lower for keyword in [\n",
    "            'pilot flying', 'pilot not flying',\n",
    "            'call \"', 'verify mode annunciation',\n",
    "            'position landing gear'\n",
    "        ]):\n",
    "            is_perf_table = False\n",
    " '''\n",
    "    ''' procedure_keywords = ['autobrake', 'pilot flying', 'descent', 'approach', 'landing roll', 'checklist']\n",
    "    if any(k in question.lower() for k in procedure_keywords):\n",
    "      disable_performance_table_bias = True\n",
    " '''\n",
    "    if is_perf_table:\n",
    "        performance_table_pages[page['page_number']] = table_info\n",
    "\n",
    "print(f\"‚úÖ Found {len(performance_table_pages)} performance table pages\")\n",
    "print(f\"\\nüìÑ Performance table pages: {list(performance_table_pages.keys())}\")\n",
    "print(f\"   Page 39 is performance table: {39 in performance_table_pages}\")\n",
    "print(f\"   Page 126 is performance table: {126 in performance_table_pages}\")\n",
    "\n",
    "by_type = defaultdict(list)\n",
    "for page_num, info in performance_table_pages.items():\n",
    "    by_type[info['type']].append(page_num)\n",
    "\n",
    "for table_type, page_nums in by_type.items():\n",
    "    print(f\"   {table_type}: {sorted(page_nums)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: IMPROVED CHUNKING STRATEGY\n",
      "================================================================================\n",
      " Chunking Complete!\n",
      "   Total chunks: 189\n",
      "   Enhanced performance table chunks: 6\n",
      "   Text chunks: 121\n",
      "   Visual chunks: 62\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: IMPROVED CHUNKING STRATEGY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: IMPROVED CHUNKING STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create a more sophisticated text splitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,  # Increased for better context\n",
    "    chunk_overlap=300,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "all_chunks = []\n",
    "enhanced_count = 0\n",
    "\n",
    "def enhance_performance_table_content(page, table_info):\n",
    "    \"\"\"Create more targeted enhancement for performance tables\"\"\"\n",
    "    table_type = table_info['type']\n",
    "    altitude = table_info.get('altitude') or 'unknown'\n",
    "    runway = table_info.get('runway_condition') or 'unknown'\n",
    "    flap = table_info.get('flap_setting') or 'all'\n",
    "\n",
    "    # Create type-specific enhancements\n",
    "    if table_type == 'field_climb_limits':\n",
    "        enhancement = f\"\"\"\n",
    "        PERFORMANCE TABLE: FIELD AND CLIMB LIMIT WEIGHTS\n",
    "        Altitude: {altitude} FT | Runway: {runway.upper()} | Flaps: {flap}\n",
    "\n",
    "        This table provides:\n",
    "        - Field limit weights based on corrected field length and OAT\n",
    "        - Climb limit weights for the specified conditions\n",
    "\n",
    "        Keywords: field limit weight, climb limit weight, {altitude} feet,\n",
    "        pressure altitude, {runway} runway, corrected field length, OAT\n",
    "\n",
    "        TABLE DATA:\n",
    "        \"\"\"\n",
    "    elif table_type == 'flap_retraction':\n",
    "        enhancement = f\"\"\"\n",
    "        PERFORMANCE TABLE: FLAP RETRACTION SPEEDS\n",
    "        This table provides flap retraction speeds for takeoff.\n",
    "\n",
    "        Keywords: flap retraction, takeoff, speed, flaps\n",
    "        \"\"\"\n",
    "    elif table_type == 'landing_limits':\n",
    "        enhancement = f\"\"\"\n",
    "        PERFORMANCE TABLE: LANDING FIELD LIMIT WEIGHTS\n",
    "        This table provides landing field limit weights with wind corrections.\n",
    "\n",
    "        Keywords: landing field limit, wind correction, landing weight\n",
    "        \"\"\"\n",
    "    else:\n",
    "        enhancement = f\"PERFORMANCE TABLE: {table_type}\\n\"\n",
    "\n",
    "    return enhancement + page['text']\n",
    "\n",
    "for page in pages:\n",
    "    if page[\"char_count\"] < 20:\n",
    "        continue\n",
    "\n",
    "    content = page[\"text\"]\n",
    "    page_num = page[\"page_number\"]\n",
    "\n",
    "    # Enhance ALL performance tables, not just field/climb limits\n",
    "    if page_num in performance_table_pages:\n",
    "        table_info = performance_table_pages[page_num]\n",
    "        enhanced_content = enhance_performance_table_content(page, table_info)\n",
    "        enhanced_count += 1\n",
    "\n",
    "        all_chunks.append({\n",
    "            \"content\": enhanced_content,\n",
    "            \"page_number\": page_num,\n",
    "            \"chunk_id\": f\"page_{page_num}_enhanced\",\n",
    "            \"type\": \"performance_table\",\n",
    "            \"page_image\": page.get(\"page_image\"),\n",
    "            \"metadata\": {\n",
    "                \"source\": \"Boeing B737 Manual\",\n",
    "                \"page\": page_num,\n",
    "                \"table_type\": table_info['type'],\n",
    "                \"altitude\": table_info.get('altitude'),\n",
    "                \"runway_condition\": table_info.get('runway_condition'),\n",
    "                \"flap_setting\": table_info.get('flap_setting')\n",
    "            }\n",
    "        })\n",
    "\n",
    "    elif page[\"is_diagram\"]:\n",
    "        # Diagrams/tables - keep whole\n",
    "        all_chunks.append({\n",
    "            \"content\": page[\"text\"],\n",
    "            \"page_number\": page_num,\n",
    "            \"chunk_id\": f\"page_{page_num}_visual\",\n",
    "            \"type\": \"visual\",\n",
    "            \"page_image\": page[\"page_image\"],\n",
    "            \"metadata\": {\n",
    "                \"source\": \"Boeing B737 Manual\",\n",
    "                \"page\": page_num,\n",
    "                \"requires_vision\": True,\n",
    "                \"ink_density\": page[\"ink_density\"]\n",
    "            }\n",
    "        })\n",
    "    else:\n",
    "        # Use semantic chunking for regular text\n",
    "        text_chunks = splitter.split_text(page[\"text\"])\n",
    "        for idx, chunk in enumerate(text_chunks):\n",
    "            all_chunks.append({\n",
    "                \"content\": chunk,\n",
    "                \"page_number\": page_num,\n",
    "                \"chunk_id\": f\"page_{page_num}_chunk_{idx}\",\n",
    "                \"type\": \"text\",\n",
    "                \"page_image\": None,\n",
    "                \"metadata\": {\n",
    "                    \"source\": \"Boeing B737 Manual\",\n",
    "                    \"page\": page_num,\n",
    "                    \"requires_vision\": False,\n",
    "                    \"chunk_index\": idx,\n",
    "                    \"total_chunks\": len(text_chunks)\n",
    "                }\n",
    "            })\n",
    "\n",
    "visual_chunks = [c for c in all_chunks if c[\"type\"] == \"visual\"]\n",
    "performance_chunks = [c for c in all_chunks if c[\"type\"] == \"performance_table\"]\n",
    "text_chunks = [c for c in all_chunks if c[\"type\"] == \"text\"]\n",
    "\n",
    "print(f\" Chunking Complete!\")\n",
    "print(f\"   Total chunks: {len(all_chunks)}\")\n",
    "print(f\"   Enhanced performance table chunks: {enhanced_count}\")\n",
    "print(f\"   Text chunks: {len(text_chunks)}\")\n",
    "print(f\"   Visual chunks: {len(visual_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: CREATE AND LOAD INDEXES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: CREATING INDEXES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def create_indexes(all_chunks):\n",
    "    \"\"\"Create and save FAISS and BM25 indexes\"\"\"\n",
    "    # Create embeddings for all chunks\n",
    "    print(\"Creating embeddings...\")\n",
    "    chunk_texts = [chunk[\"content\"] for chunk in all_chunks]\n",
    "    chunk_embeddings = embedding_model.encode(chunk_texts, show_progress_bar=True)\n",
    "\n",
    "    # Create FAISS index\n",
    "    embedding_dim = chunk_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(embedding_dim)  # Inner product for similarity\n",
    "    faiss.normalize_L2(chunk_embeddings)  # Normalize for cosine similarity\n",
    "    index.add(chunk_embeddings)\n",
    "\n",
    "    # Create BM25 index\n",
    "    print(\"Creating BM25 index...\")\n",
    "    tokenized_chunks = [chunk.lower().split() for chunk in chunk_texts]\n",
    "    bm25 = BM25Okapi(tokenized_chunks)\n",
    "\n",
    "    print(f\"‚úÖ Created FAISS index with {index.ntotal} embeddings\")\n",
    "    print(f\"‚úÖ Created BM25 index with {len(tokenized_chunks)} documents\")\n",
    "\n",
    "    # Save indexes for future use\n",
    "    faiss.write_index(index, \"boeing_manual_faiss.index\")\n",
    "    with open(\"boeing_manual_bm25.pkl\", \"wb\") as f:\n",
    "        pickle.dump(bm25, f)\n",
    "\n",
    "    with open(\"boeing_manual_chunks.pkl\", \"wb\") as f:\n",
    "        pickle.dump(all_chunks, f)\n",
    "\n",
    "    print(\"‚úÖ Saved indexes and chunks to disk\")\n",
    "\n",
    "    return index, bm25, all_chunks\n",
    "\n",
    "def load_indexes():\n",
    "    \"\"\"Load pre-built indexes from disk\"\"\"\n",
    "    try:\n",
    "        # Load FAISS index\n",
    "        index = faiss.read_index(\"boeing_manual_faiss.index\")\n",
    "\n",
    "        # Load BM25 index\n",
    "        with open(\"boeing_manual_bm25.pkl\", \"rb\") as f:\n",
    "            bm25 = pickle.load(f)\n",
    "\n",
    "        # Load chunks\n",
    "        with open(\"boeing_manual_chunks.pkl\", \"rb\") as f:\n",
    "            all_chunks = pickle.load(f)\n",
    "\n",
    "        print(\"‚úÖ Loaded existing indexes from disk\")\n",
    "        return index, bm25, all_chunks\n",
    "    except:\n",
    "        print(\"‚ùå No existing indexes found. Creating new ones...\")\n",
    "        return None, None, None\n",
    "\n",
    "index, bm25, saved_chunks = load_indexes()\n",
    "\n",
    "if index is None:\n",
    "    # Use the all_chunks created in STEP 3\n",
    "    index, bm25, all_chunks = create_indexes(all_chunks)\n",
    "else:\n",
    "    # If indexes existed, load their chunks\n",
    "    all_chunks = saved_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: CREATING INDEXES\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e45ce4d040490988f110b869b25ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0610745d015a41649ef028ba9ea6f9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1943072de0a94300aa6d331d726e8df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7666f875f33045e683aa9073c71077c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce40dae4e122478fa8f2cb11640f3077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3604f7d76c4cf7ba354d1900d2f490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e90cc6dff7e42ba87d3ffb5b792dbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c383f3c79c8d41859c4562cbb6e26517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e093bfa125d843c2ba8f2f852d8e95df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b39a2ed9eb7405593a9ab9197c0a5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83cb4d5e1ad44575a907031d5f54152b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error loading indexes: Error in faiss::FileIOReader::FileIOReader(const char*) at /project/third-party/faiss/faiss/impl/io.cpp:69: Error: 'f' failed: could not open boeing_manual_faiss.index for reading: No such file or directory\n",
      "\n",
      "üî® Building new indexes from scratch...\n",
      "üìä Processing 189 chunks from STEP 3\n",
      "Creating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec1b3e47ec34e659c1a33c4b7e958f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BM25 index...\n",
      "‚úÖ Created FAISS index with 189 embeddings\n",
      "‚úÖ Created BM25 index with 189 documents\n",
      "‚úÖ Saved indexes and chunks to disk\n",
      "\n",
      "‚úÖ Index setup complete!\n",
      "   Final chunk count: 189\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: CREATE AND LOAD INDEXES (FIXED)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: CREATING INDEXES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def create_indexes(chunks_to_index):\n",
    "    \"\"\"Create and save FAISS and BM25 indexes\"\"\"\n",
    "    if chunks_to_index is None or len(chunks_to_index) == 0:\n",
    "        raise ValueError(\"No chunks provided for indexing!\")\n",
    "\n",
    "    # Create embeddings for all chunks\n",
    "    print(\"Creating embeddings...\")\n",
    "    chunk_texts = [chunk[\"content\"] for chunk in chunks_to_index]\n",
    "    chunk_embeddings = embedding_model.encode(chunk_texts, show_progress_bar=True)\n",
    "\n",
    "    # Create FAISS index\n",
    "    embedding_dim = chunk_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(embedding_dim)  # Inner product for similarity\n",
    "    faiss.normalize_L2(chunk_embeddings)  # Normalize for cosine similarity\n",
    "    index.add(chunk_embeddings)\n",
    "\n",
    "    # Create BM25 index\n",
    "    print(\"Creating BM25 index...\")\n",
    "    tokenized_chunks = [chunk.lower().split() for chunk in chunk_texts]\n",
    "    bm25 = BM25Okapi(tokenized_chunks)\n",
    "\n",
    "    print(f\"‚úÖ Created FAISS index with {index.ntotal} embeddings\")\n",
    "    print(f\"‚úÖ Created BM25 index with {len(tokenized_chunks)} documents\")\n",
    "\n",
    "    # Save indexes for future use\n",
    "    faiss.write_index(index, \"boeing_manual_faiss.index\")\n",
    "    with open(\"boeing_manual_bm25.pkl\", \"wb\") as f:\n",
    "        pickle.dump(bm25, f)\n",
    "\n",
    "    with open(\"boeing_manual_chunks.pkl\", \"wb\") as f:\n",
    "        pickle.dump(chunks_to_index, f)\n",
    "\n",
    "    print(\"‚úÖ Saved indexes and chunks to disk\")\n",
    "\n",
    "    return index, bm25, chunks_to_index\n",
    "\n",
    "def load_indexes():\n",
    "    \"\"\"Load pre-built indexes from disk\"\"\"\n",
    "    try:\n",
    "        # Load FAISS index\n",
    "        index = faiss.read_index(\"boeing_manual_faiss.index\")\n",
    "\n",
    "        # Load BM25 index\n",
    "        with open(\"boeing_manual_bm25.pkl\", \"rb\") as f:\n",
    "            bm25 = pickle.load(f)\n",
    "\n",
    "        # Load chunks\n",
    "        with open(\"boeing_manual_chunks.pkl\", \"rb\") as f:\n",
    "            chunks = pickle.load(f)\n",
    "\n",
    "        print(\"‚úÖ Loaded existing indexes from disk\")\n",
    "        print(f\"   FAISS index size: {index.ntotal}\")\n",
    "        print(f\"   Total chunks: {len(chunks)}\")\n",
    "        return index, bm25, chunks\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå No existing indexes found: {e}\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading indexes: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Try to load existing indexes first\n",
    "loaded_index, loaded_bm25, loaded_chunks = load_indexes()\n",
    "\n",
    "if loaded_index is None:\n",
    "    # No existing indexes - create new ones using all_chunks from STEP 3\n",
    "    print(\"\\nüî® Building new indexes from scratch...\")\n",
    "\n",
    "    # Verify all_chunks exists and has content\n",
    "    if 'all_chunks' not in locals() or all_chunks is None or len(all_chunks) == 0:\n",
    "        raise ValueError(\"all_chunks from STEP 3 is not available or empty!\")\n",
    "\n",
    "    print(f\"üìä Processing {len(all_chunks)} chunks from STEP 3\")\n",
    "    index, bm25, indexed_chunks = create_indexes(all_chunks)\n",
    "else:\n",
    "    # Use loaded indexes\n",
    "    print(\"\\n‚ôªÔ∏è Using existing indexes\")\n",
    "    index = loaded_index\n",
    "    bm25 = loaded_bm25\n",
    "    all_chunks = loaded_chunks  # Update all_chunks to loaded version\n",
    "\n",
    "print(\"\\n‚úÖ Index setup complete!\")\n",
    "print(f\"   Final chunk count: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5: CONSOLIDATED QUERY FUNCTIONS\n",
      "================================================================================\n",
      "‚úÖ Consolidated query functions created\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: CONSOLIDATED QUERY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: CONSOLIDATED QUERY FUNCTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def hybrid_search(query, top_k=5, alpha=0.5):\n",
    "    \"\"\"Hybrid search combining semantic (FAISS) and keyword (BM25)\"\"\"\n",
    "\n",
    "    # Semantic search\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    query_embedding = np.array(query_embedding).astype('float32')\n",
    "    distances, indices = index.search(query_embedding, top_k * 3)\n",
    "\n",
    "    # Normalize semantic scores\n",
    "    semantic_scores = 1 / (1 + distances[0])\n",
    "    semantic_scores = semantic_scores / (semantic_scores.max() + 1e-6)\n",
    "\n",
    "    # BM25 keyword search\n",
    "    tokenized_query = query.lower().split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    bm25_scores = bm25_scores / (bm25_scores.max() + 1e-6)\n",
    "\n",
    "    # Combine scores\n",
    "    combined_scores = {}\n",
    "    for idx, score in zip(indices[0], semantic_scores):\n",
    "        combined_scores[idx] = alpha * score\n",
    "\n",
    "    for idx, score in enumerate(bm25_scores):\n",
    "        if idx in combined_scores:\n",
    "            combined_scores[idx] += (1 - alpha) * score\n",
    "        else:\n",
    "            combined_scores[idx] = (1 - alpha) * score\n",
    "\n",
    "    # Sort by combined score\n",
    "    sorted_indices = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Group by page to ensure page diversity\n",
    "    page_groups = {}\n",
    "    for idx, score in sorted_indices:\n",
    "        chunk = all_chunks[idx]\n",
    "        page_num = chunk[\"page_number\"]\n",
    "\n",
    "        if page_num not in page_groups:\n",
    "            page_groups[page_num] = {\n",
    "                \"chunks\": [],\n",
    "                \"max_score\": score,\n",
    "                \"page_num\": page_num,\n",
    "                \"semantic_score\": 0,\n",
    "                \"bm25_score\": 0\n",
    "            }\n",
    "\n",
    "        page_groups[page_num][\"chunks\"].append({\n",
    "            \"chunk_idx\": idx,\n",
    "            \"score\": score,\n",
    "            \"chunk\": chunk\n",
    "        })\n",
    "\n",
    "        if score > page_groups[page_num][\"max_score\"]:\n",
    "            page_groups[page_num][\"max_score\"] = score\n",
    "\n",
    "        # Track individual scores for diagnostics\n",
    "        if idx < len(semantic_scores):\n",
    "            page_groups[page_num][\"semantic_score\"] = max(page_groups[page_num][\"semantic_score\"], semantic_scores[idx])\n",
    "        if idx < len(bm25_scores):\n",
    "            page_groups[page_num][\"bm25_score\"] = max(page_groups[page_num][\"bm25_score\"], bm25_scores[idx])\n",
    "\n",
    "    # Sort pages by their highest scoring chunk\n",
    "    sorted_pages = sorted(page_groups.values(), key=lambda x: x[\"max_score\"], reverse=True)\n",
    "\n",
    "    # Build results with diagnostic information\n",
    "    results = []\n",
    "    for page_group in sorted_pages[:top_k]:\n",
    "        # Get the highest scoring chunk from this page\n",
    "        best_chunk = max(page_group[\"chunks\"], key=lambda x: x[\"score\"])\n",
    "        chunk = best_chunk[\"chunk\"]\n",
    "\n",
    "        results.append({\n",
    "            \"content\": chunk[\"content\"],\n",
    "            \"page_number\": page_group[\"page_num\"],\n",
    "            \"type\": chunk.get(\"type\", \"text\"),\n",
    "            \"score\": float(best_chunk[\"score\"]),\n",
    "            \"semantic_score\": float(page_group[\"semantic_score\"]),\n",
    "            \"bm25_score\": float(page_group[\"bm25_score\"]),\n",
    "            \"has_image\": chunk.get(\"page_image\") is not None,\n",
    "            \"page_image\": chunk.get(\"page_image\"),\n",
    "            \"metadata\": chunk.get(\"metadata\", {})\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "def simple_rerank(query, results, top_k=5):\n",
    "    \"\"\"Simple re-ranking based on query type\"\"\"\n",
    "\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    # Check if this is a performance table query\n",
    "    is_performance_query = any(term in query_lower for term in\n",
    "                              [\"weight\", \"limit\", \"altitude\", \"runway\", \"performance\", \"field\", \"climb\"])\n",
    "\n",
    "    # Check if this is a procedural query\n",
    "    is_procedural_query = any(term in query_lower for term in\n",
    "                             [\"procedure\", \"step\", \"checklist\", \"how to\", \"perform\"])\n",
    "\n",
    "    # Re-score based on query type\n",
    "    for result in results:\n",
    "        metadata = result.get(\"metadata\", {})\n",
    "\n",
    "        # Initialize rerank score with original score\n",
    "        rerank_score = result[\"score\"]\n",
    "\n",
    "        # Boost performance tables for performance queries\n",
    "        if is_performance_query and metadata.get(\"table_type\"):\n",
    "            rerank_score *= 1.5\n",
    "\n",
    "        # Boost procedural content for procedural queries\n",
    "        if is_procedural_query and \"procedure\" in result[\"content\"].lower():\n",
    "            rerank_score *= 1.3\n",
    "\n",
    "        # Store the rerank score\n",
    "        result[\"rerank_score\"] = rerank_score\n",
    "\n",
    "    # Sort by rerank score\n",
    "    results.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "\n",
    "    return results[:top_k]\n",
    "\n",
    "def query_boeing_manual(question, top_k=15, alpha=0.5, use_reranking=True, show_diagnostics=False):\n",
    "    \"\"\"Complete RAG query with optional re-ranking and diagnostics\"\"\"\n",
    "\n",
    "    # Step 1: Initial retrieval with hybrid search\n",
    "    results = hybrid_search(question, top_k=top_k*2, alpha=alpha)\n",
    "\n",
    "    # Step 2: Re-ranking if enabled\n",
    "    if use_reranking:\n",
    "        results = simple_rerank(question, results, len(results))\n",
    "        results = results[:top_k]\n",
    "    else:\n",
    "        results = results[:top_k]\n",
    "\n",
    "    # Step 3: Prepare context for generation\n",
    "    #page_numbers = sorted(list(set([r[\"page_number\"] for r in results])))\n",
    "    seen_pages = set()\n",
    "    page_numbers = []\n",
    "    for result in results:\n",
    "        if result[\"page_number\"] not in seen_pages:\n",
    "            page_numbers.append(result[\"page_number\"])\n",
    "            seen_pages.add(result[\"page_number\"])\n",
    "    text_parts = []\n",
    "    visual_parts = []\n",
    "\n",
    "    for rank, r in enumerate(results, 1):\n",
    "        if r[\"type\"] == \"visual\" and r[\"has_image\"]:\n",
    "            visual_parts.append((rank, r))\n",
    "        else:\n",
    "            # Include metadata in context for better understanding\n",
    "            metadata = r.get(\"metadata\", {})\n",
    "            metadata_str = \", \".join([f\"{k}: {v}\" for k, v in metadata.items() if v])\n",
    "\n",
    "            if show_diagnostics:\n",
    "                # Include diagnostic scores\n",
    "                text_parts.append(f\"[Page {r['page_number']} - Rank {rank} - Score: {r.get('rerank_score', r['score']):.3f}]\\n\"\n",
    "                                 f\"Semantic: {r.get('semantic_score', 0):.3f} | BM25: {r.get('bm25_score', 0):.3f}\\n\"\n",
    "                                 f\"Metadata: {metadata_str}\\n\"\n",
    "                                 f\"Content: {r['content']}\")\n",
    "            else:\n",
    "                # Clean version without diagnostics\n",
    "                text_parts.append(f\"[Page {r['page_number']}]\\n{r['content']}\")\n",
    "\n",
    "    context = \"\\n\\n---\\n\\n\".join(text_parts)\n",
    "\n",
    "    # Step 4: Generate answer\n",
    "    try:\n",
    "        if visual_parts:\n",
    "            model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "            parts = [f\"\"\"Answer this question about the Boeing 737 Operations Manual.\n",
    "\n",
    "            CRITICAL INSTRUCTIONS FOR READING TABLES:\n",
    "            - Look at the VISUAL table image carefully\n",
    "            - Locate the EXACT row and column specified in the question\n",
    "            - Read the value at the intersection VERY carefully\n",
    "            - Double-check you're reading the correct cell\n",
    "            - Tables may have multiple sub-columns - make sure you're in the right one\n",
    "            - If the table has poor quality text extraction, RELY ON THE IMAGE\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Text context:\n",
    "            {context}\n",
    "\n",
    "            IMPORTANT: Visual tables below are the PRIMARY source. Read them carefully:\n",
    "            \"\"\"]\n",
    "\n",
    "            for rank, vp in visual_parts:\n",
    "                img = Image.open(io.BytesIO(vp[\"page_image\"]))\n",
    "                parts.append(f\"\\n[Page {vp['page_number']} - RANK {rank}]\")\n",
    "                parts.append(img)\n",
    "                parts.append(f\"\\nExtracted text (may have OCR errors, use image if unclear):\\n{vp['content'][:1000]}\")\n",
    "                parts.append(\"\\n\\nIMPORTANT: Read the table image carefully. Verify your answer by checking the specific row and column.\")\n",
    "\n",
    "            response = model.generate_content(parts)\n",
    "            answer = response.text\n",
    "        else:\n",
    "            model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "            prompt = f\"\"\"Answer this question about the Boeing 737 Operations Manual.\n",
    "\n",
    "            CRITICAL FOR TABLES:\n",
    "            - Find the EXACT row mentioned (e.g., \"1600 meters\")\n",
    "            - Find the EXACT column mentioned (e.g., \"1000 FT\", \"WET\")\n",
    "            - Read the value at that specific intersection\n",
    "            - Be extremely precise - one cell off gives wrong answer\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Read the table precisely and provide the exact value:\"\"\"\n",
    "\n",
    "            response = model.generate_content(prompt)\n",
    "            answer = response.text\n",
    "    except Exception as e:\n",
    "        answer = f\"Error: {str(e)}\"\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"pages\": page_numbers,\n",
    "        \"results\": results if show_diagnostics else None  # Include detailed results only for diagnostics\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Consolidated query functions created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 6: TESTING FUNCTION\n",
      "================================================================================\n",
      "‚úÖ Testing function created\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: TESTING FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: TESTING FUNCTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def test_rag_system(questions, show_diagnostics=False):\n",
    "    \"\"\"Test the RAG system with optional diagnostics\"\"\"\n",
    "\n",
    "    for i, (question, expected_pages) in enumerate(questions, 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Test {i}/{len(questions)}: {question[:80]}...\")\n",
    "        print(f\"Expected pages: {expected_pages}\")\n",
    "        print('='*80)\n",
    "\n",
    "        # Get results\n",
    "        response = query_boeing_manual(question, top_k=15, alpha=0.5, use_reranking=True, show_diagnostics=show_diagnostics)\n",
    "\n",
    "        if show_diagnostics and response[\"results\"]:\n",
    "            # Print detailed results\n",
    "            print(\"\\nRetrieved pages with scores:\")\n",
    "            for j, result in enumerate(response[\"results\"][:10], 1):\n",
    "                page_num = result[\"page_number\"]\n",
    "                score = result.get(\"rerank_score\", result[\"score\"])\n",
    "                semantic_score = result.get(\"semantic_score\", 0)\n",
    "                bm25_score = result.get(\"bm25_score\", 0)\n",
    "                is_expected = \"‚úÖ\" if page_num in expected_pages else \"  \"\n",
    "\n",
    "                print(f\"  {j}. {is_expected} Page {page_num}: Total={score:.3f}, Semantic={semantic_score:.3f}, BM25={bm25_score:.3f}\")\n",
    "\n",
    "        # Check if expected pages are included\n",
    "        included = [p for p in expected_pages if p in response['pages']]\n",
    "        missing = [p for p in expected_pages if p not in response['pages']]\n",
    "\n",
    "        print(f\"\\n‚úÖ Expected pages included: {included}\")\n",
    "        print(f\"‚ùå Expected pages missing: {missing}\")\n",
    "\n",
    "        print(f\"\\nüí° Answer:\\n{response['answer']}\\n\")\n",
    "        print(f\"Result: {'‚úÖ PASS' if len(included) == len(expected_pages) else '‚ö†Ô∏è PARTIAL' if included else '‚ùå FAIL'}\")\n",
    "\n",
    "print(\"‚úÖ Testing function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API connection: API connection successful\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# GEMINI API CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Configure Gemini (update with your API key method)\n",
    "os.environ['GEMINI_API_KEY'] = 'Replace with your actual API key' \n",
    "genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "    response = model.generate_content(\"Hello, can you respond with 'API connection successful'?\")\n",
    "    print(f\"‚úÖ Gemini API connection: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to Gemini API: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 7: COMPREHENSIVE RAG SYSTEM EVALUATION (UPDATED)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 7: COMPREHENSIVE RAG SYSTEM EVALUATION (UPDATED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def evaluate_rag_system(test_questions, top_k=15, alpha=0.5, use_reranking=True):\n",
    "    \"\"\"\n",
    "    Evaluates the RAG system with a focus on user-centric metrics, all computed @5:\n",
    "    - Recall@5\n",
    "    - Precision@5\n",
    "    - F1-Score@5\n",
    "    - MRR\n",
    "    - MAP\n",
    "    \"\"\"\n",
    "    evaluation_results = []\n",
    "\n",
    "    # Lists to store metrics for each question\n",
    "    recall_at_5_list = []\n",
    "    precision_at_5_list = []\n",
    "    f1_score_list = []\n",
    "    mrr_list = []\n",
    "    map_score_list = []\n",
    "\n",
    "    print(f\"Evaluating {len(test_questions)} questions (retrieving top {top_k} results)...\")\n",
    "\n",
    "    for i, (question, expected_pages) in enumerate(test_questions, 1):\n",
    "        print(f\"\\n--- Evaluating Question {i}/{len(test_questions)} ---\")\n",
    "\n",
    "        response = query_boeing_manual(\n",
    "            question,\n",
    "            top_k=top_k,\n",
    "            alpha=alpha,\n",
    "            use_reranking=use_reranking,\n",
    "            show_diagnostics=False\n",
    "        )\n",
    "\n",
    "        retrieved_pages = response['pages']\n",
    "\n",
    "        # --- Find ranks of all correct pages ---\n",
    "        correct_ranks = [rank for rank, page_num in enumerate(retrieved_pages, 1) if page_num in expected_pages]\n",
    "\n",
    "        num_total_relevant = len(expected_pages)\n",
    "        num_relevant_in_top_5 = len([p for p in retrieved_pages[:5] if p in expected_pages])\n",
    "\n",
    "        # --- Recall@5 ---\n",
    "        recall_at_5 = num_relevant_in_top_5 / num_total_relevant if num_total_relevant > 0 else 0\n",
    "        recall_at_5_list.append(recall_at_5)\n",
    "\n",
    "        # --- Precision@5 ---\n",
    "        precision_at_5 = num_relevant_in_top_5 / 5\n",
    "        precision_at_5_list.append(precision_at_5)\n",
    "\n",
    "        # --- F1-Score@5 ---\n",
    "        if (precision_at_5 + recall_at_5) > 0:\n",
    "            f1_score = 2 * (precision_at_5 * recall_at_5) / (precision_at_5 + recall_at_5)\n",
    "        else:\n",
    "            f1_score = 0\n",
    "        f1_score_list.append(f1_score)\n",
    "\n",
    "        # --- Mean Reciprocal Rank (MRR) ---\n",
    "        first_correct_rank = correct_ranks[0] if correct_ranks else None\n",
    "        mrr_list.append(1 / first_correct_rank if first_correct_rank else 0)\n",
    "\n",
    "        # --- Average Precision (for MAP) ---\n",
    "        precisions_at_correct_docs = []\n",
    "        for rank in correct_ranks:\n",
    "            num_correct_up_to_this_rank = len([r for r in correct_ranks if r <= rank])\n",
    "            precisions_at_correct_docs.append(num_correct_up_to_this_rank / rank)\n",
    "\n",
    "        avg_precision = sum(precisions_at_correct_docs) / len(precisions_at_correct_docs) if precisions_at_correct_docs else 0\n",
    "        map_score_list.append(avg_precision)\n",
    "\n",
    "        # --- Store detailed results ---\n",
    "        evaluation_results.append({\n",
    "            \"question\": question,\n",
    "            \"expected_pages\": expected_pages,\n",
    "            \"retrieved_pages\": retrieved_pages,\n",
    "            \"correct_ranks\": correct_ranks,\n",
    "            \"recall_at_5\": recall_at_5,\n",
    "            \"precision_at_5\": precision_at_5,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"mrr\": 1 / first_correct_rank if first_correct_rank else 0,\n",
    "            \"map_score\": avg_precision\n",
    "        })\n",
    "\n",
    "        print(f\"Expected: {expected_pages} | Retrieved Top 5: {retrieved_pages[:5]}\")\n",
    "        print(f\"Recall@5: {recall_at_5:.2f} | Precision@5: {precision_at_5:.2f} | F1@5: {f1_score:.2f}\")\n",
    "\n",
    "    # --- Summary Metrics ---\n",
    "    num_questions = len(test_questions)\n",
    "    summary_metrics = {\n",
    "        \"total_questions\": num_questions,\n",
    "        \"mean_recall_at_5\": sum(recall_at_5_list) / num_questions,\n",
    "        \"mean_precision_at_5\": sum(precision_at_5_list) / num_questions,\n",
    "        \"mean_f1_score\": sum(f1_score_list) / num_questions,\n",
    "        \"mean_reciprocal_rank\": sum(mrr_list) / num_questions,\n",
    "        \"map_score\": sum(map_score_list) / num_questions\n",
    "    }\n",
    "\n",
    "    # --- Final Composite Retrieval Score ---\n",
    "    f1_weight = 0.4\n",
    "    mrr_weight = 0.4\n",
    "    map_weight = 0.2\n",
    "\n",
    "    final_retrieval_score = (\n",
    "        f1_weight * summary_metrics['mean_f1_score'] +\n",
    "        mrr_weight * summary_metrics['mean_reciprocal_rank'] +\n",
    "        map_weight * summary_metrics['map_score']\n",
    "    )\n",
    "\n",
    "    summary_metrics['final_retrieval_score'] = final_retrieval_score\n",
    "    summary_metrics['score_weights'] = {'f1': f1_weight, 'mrr': mrr_weight, 'map': map_weight}\n",
    "\n",
    "    return {\n",
    "        \"detailed_results\": evaluation_results,\n",
    "        \"summary_metrics\": summary_metrics\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated comprehensive evaluation functions created.\n"
     ]
    }
   ],
   "source": [
    "def print_evaluation_report(evaluation_results):\n",
    "    \"\"\"Prints a formatted report with the new user-centric metrics.\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE EVALUATION REPORT (FOCUSED ON RECALL@5 & PRECISION@3)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    metrics = evaluation_results['summary_metrics']\n",
    "    weights = metrics['score_weights']\n",
    "\n",
    "    print(f\"Total Questions Evaluated: {metrics['total_questions']}\")\n",
    "    print(\"\\n--- Key User-Centric Performance Metrics ---\")\n",
    "    print(f\"Mean Recall@5 (Correct page in top 5):      {metrics['mean_recall_at_5']:.2%}\")\n",
    "    print(f\"Mean Precision@5 (Correctness of top 5):    {metrics['mean_precision_at_5']:.2%}\")\n",
    "    print(\"\\n--- Core Performance Metrics ---\")\n",
    "    print(f\"Mean F1-Score@5:     {metrics['mean_f1_score']:.4f}\")\n",
    "    print(f\"Mean Reciprocal Rank (MRR):         {metrics['mean_reciprocal_rank']:.4f}\")\n",
    "    print(f\"Mean Average Precision (MAP):       {metrics['map_score']:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Final Composite Retrieval Score ---\")\n",
    "    print(f\"Formula: {weights['f1']}*F1 + {weights['mrr']}*MRR + {weights['map']}*MAP\")\n",
    "    print(f\"Final Score: {metrics['final_retrieval_score']:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Detailed Question-by-Question Analysis ---\")\n",
    "    for result in evaluation_results['detailed_results']:\n",
    "        print(f\"\\nQuestion: {result['question'][:80]}...\")\n",
    "        print(f\"  Expected: {result['expected_pages']} | Retrieved Top 5: {result['retrieved_pages'][:5]}\")\n",
    "        print(f\"  Recall@5: {result['recall_at_5']:.2f} | Precision@5: {result['precision_at_5']:.2f}\")\n",
    "\n",
    "print(\"‚úÖ Updated comprehensive evaluation functions created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RUNNING TESTS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Test 1/9: I'm calculating our takeoff weight for a dry runway. We're at 2,000 feet pressur...\n",
      "Expected pages: [83]\n",
      "================================================================================\n",
      "\n",
      "Retrieved pages with scores:\n",
      "  1.    Page 40: Total=1.169, Semantic=0.961, BM25=0.586\n",
      "  2. ‚úÖ Page 83: Total=1.045, Semantic=0.000, BM25=0.692\n",
      "  3.    Page 82: Total=1.039, Semantic=0.000, BM25=0.692\n",
      "  4.    Page 107: Total=0.889, Semantic=0.000, BM25=1.000\n",
      "  5.    Page 103: Total=0.831, Semantic=0.000, BM25=0.780\n",
      "  6.    Page 42: Total=0.790, Semantic=0.964, BM25=0.664\n",
      "  7.    Page 104: Total=0.778, Semantic=0.000, BM25=0.862\n",
      "  8.    Page 61: Total=0.761, Semantic=0.993, BM25=0.632\n",
      "  9.    Page 74: Total=0.759, Semantic=0.000, BM25=0.575\n",
      "  10.    Page 106: Total=0.741, Semantic=0.000, BM25=0.706\n",
      "\n",
      "‚úÖ Expected pages included: [83]\n",
      "‚ùå Expected pages missing: []\n",
      "\n",
      "üí° Answer:\n",
      "Based on the \"Takeoff Field & Climb Limit Weights - Dry Runway\" table for **2000 FT Pressure Altitude** on page 83, the climb limit weight at an OAT of **50¬∞C** is **52.2 (1000 KG)**.\n",
      "\n",
      "Here's how to find it:\n",
      "1.  Go to the table on page 83.\n",
      "2.  Select the table on the left, which is for **2000 FT Pressure Altitude**.\n",
      "3.  Find the column for an OAT of **50¬∞C**.\n",
      "4.  Go to the last row in that table, labeled **CLIMB LIMIT WT (1000 KG)**.\n",
      "5.  The value at the intersection of that row and column is **52.2**.\n",
      "\n",
      "Result: ‚úÖ PASS\n",
      "\n",
      "================================================================================\n",
      "Test 2/9: We're doing a Flaps 15 takeoff. Remind me, what is the first flap selection we m...\n",
      "Expected pages: [41]\n",
      "================================================================================\n",
      "\n",
      "Retrieved pages with scores:\n",
      "  1.    Page 40: Total=0.845, Semantic=0.962, BM25=0.980\n",
      "  2. ‚úÖ Page 41: Total=0.838, Semantic=0.962, BM25=1.000\n",
      "  3.    Page 67: Total=0.829, Semantic=0.000, BM25=0.724\n",
      "  4.    Page 37: Total=0.811, Semantic=0.957, BM25=0.685\n",
      "  5.    Page 54: Total=0.795, Semantic=0.982, BM25=0.802\n",
      "  6.    Page 53: Total=0.790, Semantic=0.980, BM25=0.794\n",
      "  7.    Page 65: Total=0.789, Semantic=1.000, BM25=0.662\n",
      "  8.    Page 55: Total=0.785, Semantic=0.983, BM25=0.706\n",
      "  9.    Page 64: Total=0.754, Semantic=0.998, BM25=0.625\n",
      "  10.    Page 70: Total=0.744, Semantic=0.000, BM25=0.639\n",
      "\n",
      "‚úÖ Expected pages included: [41]\n",
      "‚ùå Expected pages missing: []\n",
      "\n",
      "üí° Answer:\n",
      "Based on the \"Takeoff Flap Retraction Speed Schedule\" table on page 41, for a takeoff with Flaps 15, the first flap selection during retraction is **Flaps 5** at a speed of **V2 + 15**.\n",
      "\n",
      "Result: ‚úÖ PASS\n",
      "\n",
      "================================================================================\n",
      "Test 3/9: We're planning a Flaps 40 landing on a wet runway at a 1,000-foot pressure altit...\n",
      "Expected pages: [99]\n",
      "================================================================================\n",
      "\n",
      "Retrieved pages with scores:\n",
      "  1.    Page 86: Total=1.090, Semantic=0.000, BM25=0.737\n",
      "  2.    Page 85: Total=1.090, Semantic=0.000, BM25=0.737\n",
      "  3.    Page 83: Total=1.021, Semantic=0.000, BM25=0.637\n",
      "  4.    Page 82: Total=1.011, Semantic=0.000, BM25=0.637\n",
      "  5. ‚úÖ Page 99: Total=0.882, Semantic=0.000, BM25=1.000\n",
      "  6.    Page 107: Total=0.872, Semantic=0.000, BM25=0.990\n",
      "  7.    Page 103: Total=0.858, Semantic=0.000, BM25=0.843\n",
      "  8.    Page 106: Total=0.850, Semantic=0.000, BM25=0.869\n",
      "  9.    Page 104: Total=0.752, Semantic=0.000, BM25=0.784\n",
      "  10.    Page 105: Total=0.727, Semantic=0.000, BM25=0.564\n",
      "\n",
      "‚úÖ Expected pages included: [99]\n",
      "‚ùå Expected pages missing: []\n",
      "\n",
      "üí° Answer:\n",
      "Based on the \"Field Limit Weight (1000 KG)\" table on page 99, for a Flaps 40 landing:\n",
      "\n",
      "1.  **Locate the correct table:** The relevant table is on page 99, titled \"Landing Field Limit Weight\" and specifically the sub-table \"Field Limit Weight (1000 KG)\".\n",
      "2.  **Find the row:** Go to the row for a \"WIND CORR'D FIELD LENGTH (M)\" of **1600**.\n",
      "3.  **Find the column:** Go to the main column for \"AIRPORT PRESSURE ALTITUDE (FT)\" of **1000**, and then to the sub-column for **WET**.\n",
      "4.  **Read the value:** The value at the intersection of the 1600 row and the 1000 FT / WET column is **55.8**.\n",
      "\n",
      "Since the weight is given in 1000 KG, the field limit weight is **55,800 kg**.\n",
      "\n",
      "Result: ‚úÖ PASS\n",
      "\n",
      "================================================================================\n",
      "Test 4/9: Reviewing the standard takeoff profile: After we're airborne and get a positive ...\n",
      "Expected pages: [39, 51]\n",
      "================================================================================\n",
      "\n",
      "Retrieved pages with scores:\n",
      "  1.    Page 40: Total=1.073, Semantic=0.954, BM25=0.541\n",
      "  2. ‚úÖ Page 39: Total=0.956, Semantic=0.952, BM25=1.000\n",
      "  3.    Page 46: Total=0.929, Semantic=0.964, BM25=0.979\n",
      "  4.    Page 42: Total=0.890, Semantic=0.955, BM25=0.828\n",
      "  5.    Page 75: Total=0.877, Semantic=0.000, BM25=0.761\n",
      "  6.    Page 54: Total=0.875, Semantic=0.976, BM25=0.859\n",
      "  7.    Page 53: Total=0.871, Semantic=0.975, BM25=0.847\n",
      "  8.    Page 4: Total=0.835, Semantic=0.858, BM25=0.735\n",
      "  9.    Page 52: Total=0.828, Semantic=0.975, BM25=0.736\n",
      "  10.    Page 104: Total=0.821, Semantic=0.000, BM25=0.655\n",
      "\n",
      "‚úÖ Expected pages included: [39]\n",
      "‚ùå Expected pages missing: [51]\n",
      "\n",
      "üí° Answer:\n",
      "Based on the \"Takeoff Procedure\" on page 39, after a positive rate of climb is indicated, the Pilot Flying calls **\"GEAR UP\"**.\n",
      "\n",
      "Result: ‚ö†Ô∏è PARTIAL\n",
      "\n",
      "================================================================================\n",
      "Test 5/9: For a standard visual pattern, what three actions must be completed prior to tur...\n",
      "Expected pages: [56]\n",
      "================================================================================\n",
      "\n",
      "Retrieved pages with scores:\n",
      "  1.    Page 67: Total=0.930, Semantic=0.000, BM25=1.000\n",
      "  2. ‚úÖ Page 56: Total=0.888, Semantic=0.991, BM25=0.948\n",
      "  3.    Page 49: Total=0.843, Semantic=0.983, BM25=0.720\n",
      "  4.    Page 69: Total=0.822, Semantic=0.000, BM25=0.666\n",
      "  5.    Page 42: Total=0.822, Semantic=0.973, BM25=0.727\n",
      "  6.    Page 4: Total=0.813, Semantic=0.868, BM25=0.753\n",
      "  7.    Page 64: Total=0.807, Semantic=1.000, BM25=0.655\n",
      "  8.    Page 36: Total=0.786, Semantic=0.965, BM25=0.571\n",
      "  9.    Page 3: Total=0.784, Semantic=0.860, BM25=0.599\n",
      "  10.    Page 5: Total=0.771, Semantic=0.871, BM25=0.655\n",
      "\n",
      "‚úÖ Expected pages included: [56]\n",
      "‚ùå Expected pages missing: []\n",
      "\n",
      "üí° Answer:\n",
      "Based on the \"Visual Traffic Pattern\" diagram on page 56, the three actions that must be completed prior to turning base are:\n",
      "\n",
      "1.  **Gear down**\n",
      "2.  **Flaps 15 (landing flaps for 1 engine)**\n",
      "3.  **Arm speedbrake**\n",
      "\n",
      "Result: ‚úÖ PASS\n",
      "\n",
      "================================================================================\n",
      "Test 6/9: When the Pilot Not Flying (PNF) makes CDU entries during flight, what must the P...\n",
      "Expected pages: [5]\n",
      "================================================================================\n",
      "\n",
      "Retrieved pages with scores:\n",
      "  1. ‚úÖ Page 5: Total=0.885, Semantic=0.885, BM25=1.000\n",
      "  2.    Page 47: Total=0.763, Semantic=0.977, BM25=0.537\n",
      "  3.    Page 39: Total=0.735, Semantic=0.971, BM25=0.489\n",
      "  4.    Page 4: Total=0.722, Semantic=0.864, BM25=0.601\n",
      "  5.    Page 7: Total=0.718, Semantic=0.888, BM25=0.523\n",
      "  6.    Page 46: Total=0.691, Semantic=0.976, BM25=0.427\n",
      "  7.    Page 76: Total=0.691, Semantic=0.000, BM25=0.403\n",
      "  8.    Page 45: Total=0.688, Semantic=0.975, BM25=0.431\n",
      "  9.    Page 36: Total=0.663, Semantic=0.965, BM25=0.329\n",
      "  10.    Page 13: Total=0.652, Semantic=0.909, BM25=0.357\n",
      "\n",
      "‚úÖ Expected pages included: [5]\n",
      "‚ùå Expected pages missing: []\n",
      "\n",
      "üí° Answer:\n",
      "Based on the \"CDU Operation\" section in the provided text from the Boeing 737 Operations Manual, when the Pilot Not Flying (PNF) makes CDU entries during flight, the Pilot Flying (PF) must **verify** the entries prior to execution.\n",
      "\n",
      "The manual states: \"In flight, CDU entries are normally accomplished by the pilot not flying and verified by the pilot flying prior to execution.\"\n",
      "\n",
      "Result: ‚úÖ PASS\n",
      "\n",
      "================================================================================\n",
      "Test 7/9: I see an amber STAIRS OPER light illuminated on the forward attendant panel; wha...\n",
      "Expected pages: [126]\n",
      "================================================================================\n",
      "\n",
      "Retrieved pages with scores:\n",
      "  1. ‚úÖ Page 126: Total=0.943, Semantic=0.000, BM25=1.000\n",
      "  2.    Page 3: Total=0.744, Semantic=0.811, BM25=0.571\n",
      "  3.    Page 18: Total=0.742, Semantic=0.881, BM25=0.551\n",
      "  4.    Page 143: Total=0.735, Semantic=0.000, BM25=0.507\n",
      "  5.    Page 12: Total=0.729, Semantic=0.847, BM25=0.488\n",
      "  6.    Page 129: Total=0.714, Semantic=0.000, BM25=0.439\n",
      "  7.    Page 15: Total=0.707, Semantic=0.861, BM25=0.418\n",
      "  8.    Page 11: Total=0.692, Semantic=0.841, BM25=0.506\n",
      "  9.    Page 23: Total=0.677, Semantic=0.896, BM25=0.353\n",
      "  10.    Page 7: Total=0.666, Semantic=0.821, BM25=0.340\n",
      "\n",
      "‚úÖ Expected pages included: [126]\n",
      "‚ùå Expected pages missing: []\n",
      "\n",
      "üí° Answer:\n",
      "Based on the \"Forward Airstairs\" diagram on page 126 of the Boeing 737 Operations Manual, the amber STAIRS Operating (OPER) light indicates that the **airstair is in transit**.\n",
      "\n",
      "Result: ‚úÖ PASS\n",
      "\n",
      "================================================================================\n",
      "Test 8/9: We've just completed the engine start. What is the correct configuration for the...\n",
      "Expected pages: [35]\n",
      "================================================================================\n",
      "\n",
      "Retrieved pages with scores:\n",
      "  1. ‚úÖ Page 35: Total=1.260, Semantic=0.964, BM25=1.000\n",
      "  2.    Page 67: Total=1.203, Semantic=0.000, BM25=0.887\n",
      "  3.    Page 34: Total=1.173, Semantic=0.962, BM25=0.962\n",
      "  4.    Page 68: Total=1.136, Semantic=0.000, BM25=0.761\n",
      "  5.    Page 64: Total=1.120, Semantic=0.996, BM25=0.791\n",
      "  6.    Page 49: Total=1.099, Semantic=0.984, BM25=0.735\n",
      "  7.    Page 4: Total=1.091, Semantic=0.864, BM25=0.721\n",
      "  8.    Page 3: Total=1.086, Semantic=0.863, BM25=0.719\n",
      "  9.    Page 65: Total=1.078, Semantic=1.000, BM25=0.757\n",
      "  10.    Page 33: Total=1.074, Semantic=0.961, BM25=0.778\n",
      "\n",
      "‚úÖ Expected pages included: [35]\n",
      "‚ùå Expected pages missing: []\n",
      "\n",
      "üí° Answer:\n",
      "Based on the \"After Start Procedure\" section of the Boeing 737 Operations Manual on Page 35, the correct configuration for the ISOLATION VALVE switch is **AUTO**.\n",
      "\n",
      "Result: ‚úÖ PASS\n",
      "\n",
      "================================================================================\n",
      "Test 9/9: During the Descent and Approach procedure, what action is taken with the AUTO BR...\n",
      "Expected pages: (43, 47)\n",
      "================================================================================\n",
      "\n",
      "Retrieved pages with scores:\n",
      "  1. ‚úÖ Page 43: Total=1.258, Semantic=0.969, BM25=0.977\n",
      "  2.    Page 42: Total=1.159, Semantic=0.969, BM25=0.809\n",
      "  3.    Page 4: Total=1.142, Semantic=0.890, BM25=0.828\n",
      "  4.    Page 72: Total=1.135, Semantic=0.000, BM25=0.784\n",
      "  5. ‚úÖ Page 47: Total=1.092, Semantic=0.974, BM25=0.844\n",
      "  6.    Page 67: Total=1.081, Semantic=0.000, BM25=0.734\n",
      "  7.    Page 44: Total=1.074, Semantic=0.970, BM25=0.717\n",
      "  8.    Page 70: Total=1.073, Semantic=0.000, BM25=0.661\n",
      "  9.    Page 40: Total=1.052, Semantic=0.969, BM25=0.704\n",
      "  10.    Page 45: Total=1.047, Semantic=0.971, BM25=0.760\n",
      "\n",
      "‚úÖ Expected pages included: [43, 47]\n",
      "‚ùå Expected pages missing: []\n",
      "\n",
      "üí° Answer:\n",
      "Error: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "Result: ‚úÖ PASS\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RUN TESTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING TESTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_questions = [\n",
    "\n",
    "    (\"I'm calculating our takeoff weight for a dry runway. We're at 2,000 feet pressure altitude, and the OAT is 50¬∞C. What's the climb limit weight ?\", [83]),\n",
    "    (\"We're doing a Flaps 15 takeoff. Remind me, what is the first flap selection we make during retraction, and at what speed?\", [41]),\n",
    "    (\"We're planning a Flaps 40 landing on a wet runway at a 1,000-foot pressure altitude airport. If the wind-corrected field length is 1,600 meters, what is our field limit weight?\", [99]),\n",
    "    (\"Reviewing the standard takeoff profile: After we're airborne and get a positive rate of climb, what is the first action we take?\",[39,51]),\n",
    "    (\"For a standard visual pattern, what three actions must be completed prior to turning base?\", [56]),\n",
    "    (\"When the Pilot Not Flying (PNF) makes CDU entries during flight, what must the Pilot Flying (PF) do prior to execution\", [5]),\n",
    "    (\"I see an amber STAIRS OPER light illuminated on the forward attendant panel; what does that light indicate?\", [126]),\n",
    "    (\"We've just completed the engine start. What is the correct configuration for the ISOLATION VALVE switch during the After Start Procedure?\",[35]),\n",
    "    (\"During the Descent and Approach procedure, what action is taken with the AUTO BRAKE select switch , and what is the Pilot Flying's final action regarding the autobrake system during the Landing Roll procedure?\",[43, 47])\n",
    "\n",
    "]\n",
    "\n",
    "# Run tests with diagnostics\n",
    "test_rag_system(test_questions, show_diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 10 questions (retrieving top 10 results)...\n",
      "\n",
      "--- Evaluating Question 1/10 ---\n",
      "Expected: [83] | Retrieved Top 5: [83, 82, 107, 103, 42]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 2/10 ---\n",
      "Expected: [41] | Retrieved Top 5: [40, 41, 67, 37, 54]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 3/10 ---\n",
      "Expected: [99] | Retrieved Top 5: [86, 85, 83, 82, 99]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 4/10 ---\n",
      "Expected: [39, 51] | Retrieved Top 5: [40, 39, 46, 42, 54]\n",
      "Recall@5: 0.50 | Precision@5: 0.20 | F1@5: 0.29\n",
      "\n",
      "--- Evaluating Question 5/10 ---\n",
      "Expected: [56] | Retrieved Top 5: [67, 56, 49, 42, 4]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 6/10 ---\n",
      "Expected: [5] | Retrieved Top 5: [5, 4, 7, 46, 45]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 7/10 ---\n",
      "Expected: [126] | Retrieved Top 5: [126, 3, 18, 11, 112]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 8/10 ---\n",
      "Expected: [35] | Retrieved Top 5: [35, 67, 34, 64, 68]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 9/10 ---\n",
      "Expected: (43, 47) | Retrieved Top 5: [43, 4, 72, 47, 67]\n",
      "Recall@5: 1.00 | Precision@5: 0.40 | F1@5: 0.57\n",
      "\n",
      "--- Evaluating Question 10/10 ---\n",
      "Expected: [6] | Retrieved Top 5: [4, 139, 134, 138, 109]\n",
      "Recall@5: 0.00 | Precision@5: 0.00 | F1@5: 0.00\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE EVALUATION REPORT (FOCUSED ON RECALL@5 & PRECISION@3)\n",
      "================================================================================\n",
      "Total Questions Evaluated: 10\n",
      "\n",
      "--- Key User-Centric Performance Metrics ---\n",
      "Mean Recall@5 (Correct page in top 5):      85.00%\n",
      "Mean Precision@5 (Correctness of top 5):    20.00%\n",
      "\n",
      "--- Core Performance Metrics ---\n",
      "Mean F1-Score@5:     0.3190\n",
      "Mean Reciprocal Rank (MRR):         0.6843\n",
      "Mean Average Precision (MAP):       0.6593\n",
      "\n",
      "--- Final Composite Retrieval Score ---\n",
      "Formula: 0.4*F1 + 0.4*MRR + 0.2*MAP\n",
      "Final Score: 0.5332\n",
      "\n",
      "--- Detailed Question-by-Question Analysis ---\n",
      "\n",
      "Question: I'm calculating our takeoff weight for a dry runway. We're at 2,000 feet pressur...\n",
      "  Expected: [83] | Retrieved Top 5: [83, 82, 107, 103, 42]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: We're doing a Flaps 15 takeoff. Remind me, what is the first flap selection we m...\n",
      "  Expected: [41] | Retrieved Top 5: [40, 41, 67, 37, 54]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: We're planning a Flaps 40 landing on a wet runway at a 1,000-foot pressure altit...\n",
      "  Expected: [99] | Retrieved Top 5: [86, 85, 83, 82, 99]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: Reviewing the standard takeoff profile: After we're airborne and get a positive ...\n",
      "  Expected: [39, 51] | Retrieved Top 5: [40, 39, 46, 42, 54]\n",
      "  Recall@5: 0.50 | Precision@5: 0.20\n",
      "\n",
      "Question: For a standard visual pattern, what three actions must be completed prior to tur...\n",
      "  Expected: [56] | Retrieved Top 5: [67, 56, 49, 42, 4]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: When the Pilot Not Flying (PNF) makes CDU entries during flight, what must the P...\n",
      "  Expected: [5] | Retrieved Top 5: [5, 4, 7, 46, 45]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: I see an amber STAIRS OPER light illuminated on the forward attendant panel; wha...\n",
      "  Expected: [126] | Retrieved Top 5: [126, 3, 18, 11, 112]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: We've just completed the engine start. What is the correct configuration for the...\n",
      "  Expected: [35] | Retrieved Top 5: [35, 67, 34, 64, 68]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: During the Descent and Approach procedure, what action is taken with the AUTO BR...\n",
      "  Expected: (43, 47) | Retrieved Top 5: [43, 4, 72, 47, 67]\n",
      "  Recall@5: 1.00 | Precision@5: 0.40\n",
      "\n",
      "Question: Looking at the panel scan responsibilities for when the aircraft is stationary, ...\n",
      "  Expected: [6] | Retrieved Top 5: [4, 139, 134, 138, 109]\n",
      "  Recall@5: 0.00 | Precision@5: 0.00\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    (\"I'm calculating our takeoff weight for a dry runway. We're at 2,000 feet pressure altitude, and the OAT is 50¬∞C. What's the climb limit weight ?\", [83]),\n",
    "    (\"We're doing a Flaps 15 takeoff. Remind me, what is the first flap selection we make during retraction, and at what speed?\", [41]),\n",
    "    (\"We're planning a Flaps 40 landing on a wet runway at a 1,000-foot pressure altitude airport. If the wind-corrected field length is 1,600 meters, what is our field limit weight?\", [99]),\n",
    "    (\"Reviewing the standard takeoff profile: After we're airborne and get a positive rate of climb, what is the first action we take?\",[39,51]),\n",
    "    (\"For a standard visual pattern, what three actions must be completed prior to turning base?\", [56]),\n",
    "    (\"When the Pilot Not Flying (PNF) makes CDU entries during flight, what must the Pilot Flying (PF) do prior to execution\", [5]),\n",
    "    (\"I see an amber STAIRS OPER light illuminated on the forward attendant panel; what does that light indicate?\", [126]),\n",
    "    (\"We've just completed the engine start. What is the correct configuration for the ISOLATION VALVE switch during the After Start Procedure?\",[35]),\n",
    "    (\"During the Descent and Approach procedure, what action is taken with the AUTO BRAKE select switch , and what is the Pilot Flying's final action regarding the autobrake system during the Landing Roll procedure?\",(43, 47)),\n",
    "    (\"Looking at the panel scan responsibilities for when the aircraft is stationary, who is responsible for the forward aisle stand?\",[6])\n",
    "\n",
    "]\n",
    "# In your RUN TESTS section\n",
    "evaluation_results = evaluate_rag_system(\n",
    "    test_questions,\n",
    "    top_k=10,\n",
    "    alpha=0.5,\n",
    "    use_reranking=True\n",
    ")\n",
    "\n",
    "# Print the comprehensive report\n",
    "print_evaluation_report(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 9 questions (retrieving top 10 results)...\n",
      "\n",
      "--- Evaluating Question 1/9 ---\n",
      "Expected: [83] | Retrieved Top 5: [83, 82, 107, 103, 42]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 2/9 ---\n",
      "Expected: [41] | Retrieved Top 5: [40, 41, 67, 37, 54]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 3/9 ---\n",
      "Expected: [99] | Retrieved Top 5: [86, 85, 83, 82, 99]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 4/9 ---\n",
      "Expected: [39, 51] | Retrieved Top 5: [40, 39, 46, 42, 54]\n",
      "Recall@5: 0.50 | Precision@5: 0.20 | F1@5: 0.29\n",
      "\n",
      "--- Evaluating Question 5/9 ---\n",
      "Expected: [56] | Retrieved Top 5: [67, 56, 49, 42, 4]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 6/9 ---\n",
      "Expected: [5] | Retrieved Top 5: [5, 4, 7, 46, 45]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 7/9 ---\n",
      "Expected: [126] | Retrieved Top 5: [126, 3, 18, 11, 112]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 8/9 ---\n",
      "Expected: [35] | Retrieved Top 5: [35, 67, 34, 64, 68]\n",
      "Recall@5: 1.00 | Precision@5: 0.20 | F1@5: 0.33\n",
      "\n",
      "--- Evaluating Question 9/9 ---\n",
      "Expected: (43, 47) | Retrieved Top 5: [43, 4, 72, 47, 67]\n",
      "Recall@5: 1.00 | Precision@5: 0.40 | F1@5: 0.57\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE EVALUATION REPORT (FOCUSED ON RECALL@5 & PRECISION@3)\n",
      "================================================================================\n",
      "Total Questions Evaluated: 9\n",
      "\n",
      "--- Key User-Centric Performance Metrics ---\n",
      "Mean Recall@5 (Correct page in top 5):      94.44%\n",
      "Mean Precision@5 (Correctness of top 5):    22.22%\n",
      "\n",
      "--- Core Performance Metrics ---\n",
      "Mean F1-Score@10:     0.3545\n",
      "Mean Reciprocal Rank (MRR):         0.7444\n",
      "Mean Average Precision (MAP):       0.7167\n",
      "\n",
      "--- Final Composite Retrieval Score ---\n",
      "Formula: 0.4*F1 + 0.4*MRR + 0.2*MAP\n",
      "Final Score: 0.5829\n",
      "\n",
      "--- Detailed Question-by-Question Analysis ---\n",
      "\n",
      "Question: I'm calculating our takeoff weight for a dry runway. We're at 2,000 feet pressur...\n",
      "  Expected: [83] | Retrieved Top 5: [83, 82, 107, 103, 42]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: We're doing a Flaps 15 takeoff. Remind me, what is the first flap selection we m...\n",
      "  Expected: [41] | Retrieved Top 5: [40, 41, 67, 37, 54]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: We're planning a Flaps 40 landing on a wet runway at a 1,000-foot pressure altit...\n",
      "  Expected: [99] | Retrieved Top 5: [86, 85, 83, 82, 99]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: Reviewing the standard takeoff profile: After we're airborne and get a positive ...\n",
      "  Expected: [39, 51] | Retrieved Top 5: [40, 39, 46, 42, 54]\n",
      "  Recall@5: 0.50 | Precision@5: 0.20\n",
      "\n",
      "Question: For a standard visual pattern, what three actions must be completed prior to tur...\n",
      "  Expected: [56] | Retrieved Top 5: [67, 56, 49, 42, 4]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: When the Pilot Not Flying (PNF) makes CDU entries during flight, what must the P...\n",
      "  Expected: [5] | Retrieved Top 5: [5, 4, 7, 46, 45]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: I see an amber STAIRS OPER light illuminated on the forward attendant panel; wha...\n",
      "  Expected: [126] | Retrieved Top 5: [126, 3, 18, 11, 112]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: We've just completed the engine start. What is the correct configuration for the...\n",
      "  Expected: [35] | Retrieved Top 5: [35, 67, 34, 64, 68]\n",
      "  Recall@5: 1.00 | Precision@5: 0.20\n",
      "\n",
      "Question: During the Descent and Approach procedure, what action is taken with the AUTO BR...\n",
      "  Expected: (43, 47) | Retrieved Top 5: [43, 4, 72, 47, 67]\n",
      "  Recall@5: 1.00 | Precision@5: 0.40\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    (\"I'm calculating our takeoff weight for a dry runway. We're at 2,000 feet pressure altitude, and the OAT is 50¬∞C. What's the climb limit weight ?\", [83]),\n",
    "    (\"We're doing a Flaps 15 takeoff. Remind me, what is the first flap selection we make during retraction, and at what speed?\", [41]),\n",
    "    (\"We're planning a Flaps 40 landing on a wet runway at a 1,000-foot pressure altitude airport. If the wind-corrected field length is 1,600 meters, what is our field limit weight?\", [99]),\n",
    "    (\"Reviewing the standard takeoff profile: After we're airborne and get a positive rate of climb, what is the first action we take?\",[39,51]),\n",
    "    (\"For a standard visual pattern, what three actions must be completed prior to turning base?\", [56]),\n",
    "    (\"When the Pilot Not Flying (PNF) makes CDU entries during flight, what must the Pilot Flying (PF) do prior to execution\", [5]),\n",
    "    (\"I see an amber STAIRS OPER light illuminated on the forward attendant panel; what does that light indicate?\", [126]),\n",
    "    (\"We've just completed the engine start. What is the correct configuration for the ISOLATION VALVE switch during the After Start Procedure?\",[35]),\n",
    "    (\"During the Descent and Approach procedure, what action is taken with the AUTO BRAKE select switch , and what is the Pilot Flying's final action regarding the autobrake system during the Landing Roll procedure?\",(43, 47)),\n",
    "    (\"Looking at the panel scan responsibilities for when the aircraft is stationary, who is responsible for the forward aisle stand?\",[6])\n",
    "\n",
    "]\n",
    "# In your RUN TESTS section\n",
    "evaluation_results = evaluate_rag_system(\n",
    "    test_questions,\n",
    "    top_k=10,\n",
    "    alpha=0.5,\n",
    "    use_reranking=True\n",
    ")\n",
    "\n",
    "# Print the comprehensive report\n",
    "print_evaluation_report(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 9 questions (retrieving top 10 results)...\n",
      "\n",
      "--- Evaluating Question 1/9 ---\n",
      "Expected: [83] | Retrieved Top 5: [83, 82, 107, 103, 42]\n",
      "Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "--- Evaluating Question 2/9 ---\n",
      "Expected: [41] | Retrieved Top 5: [40, 41, 67, 37, 54]\n",
      "Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "--- Evaluating Question 3/9 ---\n",
      "Expected: [99] | Retrieved Top 5: [86, 85, 83, 82, 99]\n",
      "Recall@5: 1.00 | Precision@3: 0.00\n",
      "\n",
      "--- Evaluating Question 4/9 ---\n",
      "Expected: [39, 51] | Retrieved Top 5: [40, 39, 46, 42, 54]\n",
      "Recall@5: 0.50 | Precision@3: 0.33\n",
      "\n",
      "--- Evaluating Question 5/9 ---\n",
      "Expected: [56] | Retrieved Top 5: [67, 56, 49, 42, 4]\n",
      "Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "--- Evaluating Question 6/9 ---\n",
      "Expected: [5] | Retrieved Top 5: [5, 4, 7, 46, 45]\n",
      "Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "--- Evaluating Question 7/9 ---\n",
      "Expected: [126] | Retrieved Top 5: [126, 3, 18, 11, 112]\n",
      "Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "--- Evaluating Question 8/9 ---\n",
      "Expected: [35] | Retrieved Top 5: [35, 67, 34, 64, 68]\n",
      "Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "--- Evaluating Question 9/9 ---\n",
      "Expected: (43, 47) | Retrieved Top 5: [43, 4, 72, 47, 67]\n",
      "Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE EVALUATION REPORT (FOCUSED ON RECALL@5 & PRECISION@3)\n",
      "================================================================================\n",
      "Total Questions Evaluated: 9\n",
      "\n",
      "--- Key User-Centric Performance Metrics ---\n",
      "Mean Recall@5 (Correct page in top 5):      94.44%\n",
      "Mean Precision@3 (Correctness of top 3):    29.63%\n",
      "\n",
      "--- Core Performance Metrics ---\n",
      "Mean F1-Score@10:     0.1970\n",
      "Mean Reciprocal Rank (MRR):         0.7444\n",
      "Mean Average Precision (MAP):       0.7167\n",
      "\n",
      "--- Final Composite Retrieval Score ---\n",
      "Formula: 0.4*F1 + 0.4*MRR + 0.2*MAP\n",
      "Final Score: 0.5199\n",
      "\n",
      "--- Detailed Question-by-Question Analysis ---\n",
      "\n",
      "Question: I'm calculating our takeoff weight for a dry runway. We're at 2,000 feet pressur...\n",
      "  Expected: [83] | Retrieved Top 5: [83, 82, 107, 103, 42]\n",
      "  Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "Question: We're doing a Flaps 15 takeoff. Remind me, what is the first flap selection we m...\n",
      "  Expected: [41] | Retrieved Top 5: [40, 41, 67, 37, 54]\n",
      "  Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "Question: We're planning a Flaps 40 landing on a wet runway at a 1,000-foot pressure altit...\n",
      "  Expected: [99] | Retrieved Top 5: [86, 85, 83, 82, 99]\n",
      "  Recall@5: 1.00 | Precision@3: 0.00\n",
      "\n",
      "Question: Reviewing the standard takeoff profile: After we're airborne and get a positive ...\n",
      "  Expected: [39, 51] | Retrieved Top 5: [40, 39, 46, 42, 54]\n",
      "  Recall@5: 0.50 | Precision@3: 0.33\n",
      "\n",
      "Question: For a standard visual pattern, what three actions must be completed prior to tur...\n",
      "  Expected: [56] | Retrieved Top 5: [67, 56, 49, 42, 4]\n",
      "  Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "Question: When the Pilot Not Flying (PNF) makes CDU entries during flight, what must the P...\n",
      "  Expected: [5] | Retrieved Top 5: [5, 4, 7, 46, 45]\n",
      "  Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "Question: I see an amber STAIRS OPER light illuminated on the forward attendant panel; wha...\n",
      "  Expected: [126] | Retrieved Top 5: [126, 3, 18, 11, 112]\n",
      "  Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "Question: We've just completed the engine start. What is the correct configuration for the...\n",
      "  Expected: [35] | Retrieved Top 5: [35, 67, 34, 64, 68]\n",
      "  Recall@5: 1.00 | Precision@3: 0.33\n",
      "\n",
      "Question: During the Descent and Approach procedure, what action is taken with the AUTO BR...\n",
      "  Expected: (43, 47) | Retrieved Top 5: [43, 4, 72, 47, 67]\n",
      "  Recall@5: 1.00 | Precision@3: 0.33\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    (\"I'm calculating our takeoff weight for a dry runway. We're at 2,000 feet pressure altitude, and the OAT is 50¬∞C. What's the climb limit weight ?\", [83]),\n",
    "    (\"We're doing a Flaps 15 takeoff. Remind me, what is the first flap selection we make during retraction, and at what speed?\", [41]),\n",
    "    (\"We're planning a Flaps 40 landing on a wet runway at a 1,000-foot pressure altitude airport. If the wind-corrected field length is 1,600 meters, what is our field limit weight?\", [99]),\n",
    "    (\"Reviewing the standard takeoff profile: After we're airborne and get a positive rate of climb, what is the first action we take?\",[39,51]),\n",
    "    (\"For a standard visual pattern, what three actions must be completed prior to turning base?\", [56]),\n",
    "    (\"When the Pilot Not Flying (PNF) makes CDU entries during flight, what must the Pilot Flying (PF) do prior to execution\", [5]),\n",
    "    (\"I see an amber STAIRS OPER light illuminated on the forward attendant panel; what does that light indicate?\", [126]),\n",
    "    (\"We've just completed the engine start. What is the correct configuration for the ISOLATION VALVE switch during the After Start Procedure?\",[35]),\n",
    "    (\"During the Descent and Approach procedure, what action is taken with the AUTO BRAKE select switch , and what is the Pilot Flying's final action regarding the autobrake system during the Landing Roll procedure?\",(43, 47))\n",
    "\n",
    "]\n",
    "# In your RUN TESTS section\n",
    "evaluation_results = evaluate_rag_system(\n",
    "    test_questions,\n",
    "    top_k=10,\n",
    "    alpha=0.5,\n",
    "    use_reranking=True\n",
    ")\n",
    "\n",
    "# Print the comprehensive report\n",
    "print_evaluation_report(evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vElBvlmKT5jd"
   },
   "source": [
    "##REranking with cross_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ad389081b24da9809c9be6a9ab88f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6875c0ce481c41dfb07f1403b01ecabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2c218eb26c48568a00ff7839ec43e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557f40993e4c492eab317a6a2b62d41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb74bda15833450c9d867094ff33e162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9764ae0dc11942e38c2f9c7a8fb704e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d194dada334488a213e220946d1a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OPTION 1: Cross-Encoder Reranking (Best Performance)\n",
    "# ============================================================================\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Initialize once at startup\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "def cross_encoder_rerank(query, results, top_k=5):\n",
    "    \"\"\"\n",
    "    Uses a trained cross-encoder to score query-document pairs.\n",
    "    Much more accurate than rule-based scoring.\n",
    "    \"\"\"\n",
    "    # Prepare query-document pairs\n",
    "    pairs = [[query, result[\"content\"][:512]] for result in results]\n",
    "\n",
    "    # Get relevance scores from cross-encoder\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "\n",
    "    # Add scores to results\n",
    "    for result, score in zip(results, scores):\n",
    "        result[\"rerank_score\"] = float(score)\n",
    "\n",
    "    # Sort by rerank score\n",
    "    results.sort(key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "\n",
    "    return results[:top_k]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_boeing_manual(question, top_k=15, alpha=0.5, use_reranking=True, show_diagnostics=False):\n",
    "    \"\"\"Complete RAG query with optional re-ranking and diagnostics\"\"\"\n",
    "\n",
    "    # Step 1: Initial retrieval with hybrid search\n",
    "    results = hybrid_search(question, top_k=top_k*2, alpha=alpha)\n",
    "\n",
    "    # Step 2: Re-ranking if enabled\n",
    "    if use_reranking:\n",
    "        results = cross_encoder_rerank(question, results, top_k)\n",
    "    else:\n",
    "        results = results[:top_k]\n",
    "\n",
    "    # Step 3: Prepare context for generation\n",
    "    #page_numbers = sorted(list(set([r[\"page_number\"] for r in results])))\n",
    "    seen_pages = set()\n",
    "    page_numbers = []\n",
    "    for result in results:\n",
    "        if result[\"page_number\"] not in seen_pages:\n",
    "            page_numbers.append(result[\"page_number\"])\n",
    "            seen_pages.add(result[\"page_number\"])\n",
    "    text_parts = []\n",
    "    visual_parts = []\n",
    "\n",
    "    for rank, r in enumerate(results, 1):\n",
    "        if r[\"type\"] == \"visual\" and r[\"has_image\"]:\n",
    "            visual_parts.append((rank, r))\n",
    "        else:\n",
    "            # Include metadata in context for better understanding\n",
    "            metadata = r.get(\"metadata\", {})\n",
    "            metadata_str = \", \".join([f\"{k}: {v}\" for k, v in metadata.items() if v])\n",
    "\n",
    "            if show_diagnostics:\n",
    "                # Include diagnostic scores\n",
    "                text_parts.append(f\"[Page {r['page_number']} - Rank {rank} - Score: {r.get('rerank_score', r['score']):.3f}]\\n\"\n",
    "                                 f\"Semantic: {r.get('semantic_score', 0):.3f} | BM25: {r.get('bm25_score', 0):.3f}\\n\"\n",
    "                                 f\"Metadata: {metadata_str}\\n\"\n",
    "                                 f\"Content: {r['content']}\")\n",
    "            else:\n",
    "                # Clean version without diagnostics\n",
    "                text_parts.append(f\"[Page {r['page_number']}]\\n{r['content']}\")\n",
    "\n",
    "    context = \"\\n\\n---\\n\\n\".join(text_parts)\n",
    "\n",
    "    # Step 4: Generate answer\n",
    "    try:\n",
    "        if visual_parts:\n",
    "            model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "            parts = [f\"\"\"Answer this question about the Boeing 737 Operations Manual.\n",
    "\n",
    "            CRITICAL INSTRUCTIONS FOR READING TABLES:\n",
    "            - Look at the VISUAL table image carefully\n",
    "            - Locate the EXACT row and column specified in the question\n",
    "            - Read the value at the intersection VERY carefully\n",
    "            - Double-check you're reading the correct cell\n",
    "            - Tables may have multiple sub-columns - make sure you're in the right one\n",
    "            - If the table has poor quality text extraction, RELY ON THE IMAGE\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Text context:\n",
    "            {context}\n",
    "\n",
    "            IMPORTANT: Visual tables below are the PRIMARY source. Read them carefully:\n",
    "            \"\"\"]\n",
    "\n",
    "            for rank, vp in visual_parts:\n",
    "                img = Image.open(io.BytesIO(vp[\"page_image\"]))\n",
    "                parts.append(f\"\\n[Page {vp['page_number']} - RANK {rank}]\")\n",
    "                parts.append(img)\n",
    "                parts.append(f\"\\nExtracted text (may have OCR errors, use image if unclear):\\n{vp['content'][:1000]}\")\n",
    "                parts.append(\"\\n\\nIMPORTANT: Read the table image carefully. Verify your answer by checking the specific row and column.\")\n",
    "\n",
    "            response = model.generate_content(parts)\n",
    "            answer = response.text\n",
    "        else:\n",
    "            model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "            prompt = f\"\"\"Answer this question about the Boeing 737 Operations Manual.\n",
    "\n",
    "            CRITICAL FOR TABLES:\n",
    "            - Find the EXACT row mentioned (e.g., \"1600 meters\")\n",
    "            - Find the EXACT column mentioned (e.g., \"1000 FT\", \"WET\")\n",
    "            - Read the value at that specific intersection\n",
    "            - Be extremely precise - one cell off gives wrong answer\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Read the table precisely and provide the exact value:\"\"\"\n",
    "\n",
    "            response = model.generate_content(prompt)\n",
    "            answer = response.text\n",
    "    except Exception as e:\n",
    "        answer = f\"Error: {str(e)}\"\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"pages\": page_numbers,\n",
    "        \"results\": results if show_diagnostics else None  # Include detailed results only for diagnostics\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
